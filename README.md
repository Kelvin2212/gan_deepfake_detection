# MRI-GAN: A Generalized Approach to Detect DeepFakes using Perceptual Image Assessment


This readme file described steps needed to replicate the work, either from scratch or using pre-trained models. 'From scratch' is very involved process and includes training of all the models. In either case data processing needs to be done. Details are described below.

**TLDR.**
## Abstract
DeepFakes are synthetic videos generated by swapping a face of an original image with the face of somebody else. In this paper, we describe our work to develop general, deep learning-based models to classify DeepFake content. We propose a novel framework for using Generative Adversar-ial Network (GAN)-based models, we call MRI-GAN, that utilizes perceptual differences in images to detect synthesized videos. We test our MRI-GAN approach and a plain-frames-based model using the DeepFake Detection Challenge Dataset. Our plain frames-based-model achieves 91% test accuracy and a model which uses our MRI-GAN framework with Structural Similarity Index Measurement (SSIM) for the perceptual differences achieves 74% test accuracy. The results of MRI-GAN are preliminary and maybe improved further by modifying the choice of loss function, tuning hyper-parameters, or by using a more advanced perceptual similarity metric.

## To replicate the overall work from scratch, below steps need to be performed.

Note: This is very involved process.

1. Download datasets and extract.
    1. DFDC dataset from https://ai.facebook.com/datasets/dfdc/
    1. Celeb-DF-v2 dataset from https://github.com/yuezunli/celeb-deepfakeforensics
    1. FFHQ dataset from https://github.com/NVlabs/ffhq-dataset
    1. FDF dataset from https://github.com/hukkelas/FDF
1. Configure the paths and other params.
    1. `config.yml` is the key configuration to control the whole flow. Update paths of the dataset paths as needed. You would need to update all the paths which starts from /home/directory, other filenames does not need be changed.  
    1. DFDC dataset configuration
        1. ['data_path']['dfdc']['train'] : path of the training set
        1. ['data_path']['dfdc']['valid'] : path of the validation set
        1. ['data_path']['dfdc']['test'] : path of the test set
    1. Celeb-DF-v2  dataset configuration.
        1. ['data_path']['celeb_df_v2']['real'] : path of real samples (Celeb-real)
        1. ['data_path']['celeb_df_v2']['fake'] : path of fake samples (Celeb-synthesis)
    1. FDF dataset configuration.
        1. ['data_path']['fdf']['data_path'] : path of samples (cc-by-nc-sa-2/128)
    1. FFHQ dataset configuration.
        1. ['data_path']['ffhq']['data_path'] : path of samples (images1024x1024)
1.  Data pre-processing. Enter following commands in sequence
    1. `python data_preprocess.py --gen_aug_plan` (select random video files in the DFDC training set and make a plan to apply various 
       random combinations of augmentation and distractions. This commands generates the plan and saves in a .pkl file.) 
    1. `python data_preprocess.py --apply_aug_to_all` (Execute the plan generated in step #1. This commands read the .pkl file
       generated in step #1 and executes the plan one-by-one for each video file selected in DFDC training set)
    1. `python data_preprocess.py --extract_landmarks` (Use pre-trained MTCNN to extract landmarks of each faces detected in the video frames.
       Every 10th frame is used by default in each video. Landmarks are extracted for each video in train, validation and test set. All landmarks
       are saved in separate .json files for each video)
    1. `python data_preprocess.py --crop_faces` (Save faces from landmarks json files for each video)
    1. `python data_preprocess.py --gen_mri_dataset` (Generate MRI-DF dataset. This generates the images of perceptual dissimilarity for DFDC train 
       set -(50% of ))

1.  MRI-GAN training
    1. Configure `config.yml`. Parameters under ['MRI_GAN']['model_params'] section can be tweaked. 'tau' is adjusted for different results.
       'batch_size' can be changed depending upon GPU memory available for your machine.
    1. `python train_MRI_GAN.py --train_from_scratch` (Train the MRI-GAN model. Check help for option on --train_resume to resume training 
       if it was stopped earlier. Logs will generated and saved under logs/<date_time_stamp> directory, model weights will also be saved in the same directory)
    1. `cp logs/<date_time_stamp>/MRI_GAN/checkpoint_best_G.chkpt assets/weights/MRI_GAN_weights.chkpt` (Copy trained MRI-GAN weights)
    1. `python data_preprocess.py --gen_dfdc_mri` (Use trained MRI-GAN to predict MRIs for DFDC dataset) 

1. Train and test the DeepFake Detection model
    1. `python data_preprocess.py --gen_deepfake_metadata` (Generate metadata csv files used by DataLoaders of PyTorch classes)
    1.  Using plain-frames method
        1. Configure `config.yml`. Parameters under ['deep_fake']['model_params'] section can be tweaked. For plain-frames method set following params. 
           'train_transform' : 'complex'
           'dataset' : 'plain'
           'batch_size' can be changed depending upon GPU memory available for your machine.
        1. `python deep_fake_detect.py --train_from_scratch` (Start training from scratch. Also check `--train_resume` command line option if you want to resume previosuly strarted training. After all epochs are done, testing of the model will start)
        1. `python deep_fake_detect.py --test_saved_model <path>` (Test the model which was saved on disk. e.g. if the training was killed before all epocs were compepleted, this option can be used to test the model which was saved during training process)
    1.  Using MRI-based method
        1. Configure `config.yml`. Parameters under ['deep_fake']['model_params'] section can be tweaked. For plain-frames method set following params. 
           'train_transform' : 'simple'
           'dataset' : 'mri'
           'batch_size' can be changed depending upon GPU memory available for your machine.
        1. `python deep_fake_detect.py --train_from_scratch` (Start training from scratch. Also check `--train_resume` command line option if you want to resume previosuly strarted training. After all epochs are done, testing of the model will start)
        1. `python deep_fake_detect.py --test_saved_model <path>` (Test the model which was saved on disk. e.g. if the training was killed before all epocs were compepleted, this option can be used to test the model which was saved during training process)



### Other Notes
* check --help of all scripts mentioned above to see more utility methods, e.g. to resume training of models if the trained was stopped in between.

